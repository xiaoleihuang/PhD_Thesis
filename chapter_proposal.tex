\chapter{User Embedding}
\label{chp:userEmbed}

\section{Motivation}
User behaviors including personal interests and sentiment expressions change over time. 
Most of existing research only models the static user behaviors without considering the temporal variations and it is hard to model the dynamic user behaviors over time by the static user embeddings~\cite{pan2019social}.
Therefore, it is desirable to model the temporal variations into the user embedding.
In this thesis, we propose a method that explicitly incorporate user behavior dynamics into user embedding, \textit{dynamic user embedding}.

Additionally, user behaviors vary across different demographic groups.
Yet, existing methods do not explicitly model the demographic attributes into user embedding models. 
We call the process of incorporating user demographic factors as \textit{user factor adaptation}.
In this proposal, we adapt the demographic attributes via a multitask framework  into user embedding, \textit{demographic user embedding}.  



\section{Data}
To evaluate the user embedding models, we plan to use the previous Yelp and Amazon reviews datasets~\cite{huang2019neuraluser} including both user information and scored reviews, such as purchasing records, item reviews and ratings, user demographic information and user friendship.
The dataset contains over 800K user entries and 1 million reviews.


\section{Dynamic User Embedding}

To model the temporal user behaviors, we first cut user behaviors into continuous time intervals, such as by season, year or couple of years.
Next, we build an user embedding model separate for each time interval.
One critical issue with the embedding models is how to align continuously them together.
We plan to adopt the existing methods of training dynamic word embeddings~\cite{kutuzov2018diachronic} including incremental training~\cite{kim2014temporal}, linear alignment~\cite{kulkarni2015statistically} and orthogonal Procrustes~\cite{hamilton2016diachronic} as baselines.
Particularly, we propose to vectorize both user and time as embeddings, then the dynamic user embedding can be represented as following:
$$U(u_i, t) = \sigma(U(u_i)*W_u + T(t)*W_t)$$
, where $U$ is the user embedding, $T$ is the time embedding, and $\sigma$ is an activation function to jointly integrate user and time representations.
We can train and initialize the user embedding by the existing methods such as Word2vec~\cite{amir2016modelling} and averaged contextualized embeddings~\cite{devlin2019bert}.
Finally, we can optimize the dynamic user embeddings $U(u_i, t)$ by word usage prediction~\cite{amir2016modelling}.


\section{Demographic User Embedding}
User usually have multiple attributes.
We plan to use multitask learning~\cite{huang2019neuraluser} to integrate user attributes jointly into user embeddings, which not only we have Skip-gram~\cite{mikolov2013distributed} modeling user language behaviors, but also we will set demographic prediction as auxiliary optimizing tasks:
$$ \mathcal{L} = \mathcal{L}(y, \hat{y}) + \sum_{d \in D}\mathcal{L}(y_d, \hat{y}_d)$$
, where $\mathcal{L}(y, \hat{y})$ is the loss value of document class prediction, and $\mathcal{L}(y_d, \hat{y}_d)$ is the loss value of user demographic prediction.


\section{Evaluation}

\textit{User Engagement Prediction} is to predict if user will take targeted actions such as activities participation or item purchases~\cite{benton2016learning}.
The review datasets record their purchase behaviors overtime, therefore, the evaluations can have two levels of tasks: whether users will purchase the items and if users will give a positive rate.

\textit{User State Prediction} is to predict the current user state, such as sentiment scores. One of our aims is to evaluate if the user embeddings can improve the performance or reduce biases of document classifiers. Therefore, we can can first convert the state prediction into sentiment classification and then follow the evaluation methods of document classification in Chapter~\ref{chap2:subsec:eval}.


\section{Timeline}

% more specific information of every step

\begin{itemize}
    \item October: Data collection and baselines, including non-dynamic~\cite{benton2016learning, amir2016modelling} and dynamic user embedding~\cite{liang2018dynamic, kumar2019predicting};
    \item November: Baselines and model implementation;
    \item December: Paper writing and submission. The target is ACL'20 (Dec 2019) or COLING'20 (April 2020) or data mining related conferences, such as KDD'20 (Feb. 2020).
\end{itemize}
